{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの検証方法とチューニング方法\n",
    "\n",
    "### モデルの評価方法と精度を上げる方法\n",
    "- 機械学習の課題とアプローチ\n",
    "\n",
    "### モデルの評価とパフォーマンスチューニング\n",
    "- ホールドアウト法と交差検証法\n",
    "- パフォーマンスチューニング：　ハイパーパラメータチューニング\n",
    "- パフォーマンスチューニング：　特徴量の扱い\n",
    "- モデルの種類\n",
    "\n",
    "### モデルの評価指標\n",
    "- 分類モデルの評価：　混同行列と関連指標\n",
    "- 分類モデルの評価：　ROC曲線とAUC\n",
    "- 回帰モデルの評価指標\n",
    "\n",
    "### アンサンブル学習\n",
    "- バギング\n",
    "- ブースティング\n",
    "- ランダムフォレスト、勾配ブースティング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習の課題とアプローチ\n",
    "1. 新しいデータに適合できない場合（過学習/オーバーフィッティング）：ホールドアウト法（テストデータ用にデータを抜き出しておく）や交差検証法\n",
    "2. モデルの良さを判定する指標や方法：混同行列やROC曲線\n",
    "3. 精度が高いモデルを作成する：アンサンブル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ加工・処理・分析ライブラリ\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import scipy as sp\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# 可視化ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# 機械学習ライブラリ\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交差検証法\n",
    "データ数が限られるときは、2つの問題が生じます。ひとつは、ランダムに分割された特定のテストデータによっては、たまたま高く評価されてしまう問題です。もうひとつは、限られたデータを学習用とテスト用に分割するため、学習データ数が削られ、肝心の学習が十分に進まないという問題です。\n",
    "\n",
    "そこで、限られたデータを最大限に活用しようと考案されたのが交差検証法（cross validation）です。これはデータの役割を学習用と検証用に交差させる検証法です。交差検証法の代表的な手法にk分割交差検証（k-fold cross validation）があります。この手法では、データをk個のブロックにランダムに分割します。そして、k個のうち1つのブロックを検証用、残りの 𝑘−1 個を学習用として活用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [0.90350877 0.9122807  0.95614035 0.93859649 0.95575221]\n",
      "Cross validation scores: 0.933+-0.022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "\n",
    "scores = cross_val_score(tree, cancer.data, cancer.target, cv=5)\n",
    "\n",
    "print('Cross validation scores: {}'.format(scores))\n",
    "print('Cross validation scores: {:.3f}+-{:.3f}'.format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パフォーマンスチューニング：ハイパーパラメータチューニング\n",
    "そもそものモデルの汎化性能を向上させるための手法、具合的には、アルゴリズムが固有に持つハイパーパラメータのチューニング手法である、グリッドサーチ（grid search）について学びます。\n",
    "\n",
    "既に学んだように、各アルゴリズムは固有のパラメータを持っています。これは、係数のような値を推定するパラメータではなく、あらかじめ人が決めることが多く、ハイパーパラメータといって区別します。\n",
    "\n",
    "グリッドサーチは、注目するいくつかのハイパーパラメータのすべての組み合わせについて交差検証を行い、最も性能の高いパラメータの組み合わせを探索してベストモデルの学習をするものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
