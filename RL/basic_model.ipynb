{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "train mean loss=2.279682780901591, accuracy=0.13593333333333332\n",
      "test  mean loss=2.2791626548767088, accuracy=0.1391\n",
      "epoch 2\n",
      "train mean loss=2.2423453271389007, accuracy=0.4139\n",
      "test  mean loss=2.241023504734039, accuracy=0.4299\n",
      "epoch 3\n",
      "train mean loss=2.1733042176564537, accuracy=0.5427166666666666\n",
      "test  mean loss=2.170335741043091, accuracy=0.5607\n",
      "epoch 4\n",
      "train mean loss=2.0200047332048414, accuracy=0.5866666666666667\n",
      "test  mean loss=2.013285748958588, accuracy=0.6023\n",
      "epoch 5\n",
      "train mean loss=1.6696142943700154, accuracy=0.65345\n",
      "test  mean loss=1.6551183116436006, accuracy=0.6684\n",
      "epoch 6\n",
      "train mean loss=1.151223659813404, accuracy=0.76055\n",
      "test  mean loss=1.1290216207504273, accuracy=0.774\n",
      "epoch 7\n",
      "train mean loss=0.7765299517909686, accuracy=0.82175\n",
      "test  mean loss=0.7543489119410515, accuracy=0.8308\n",
      "epoch 8\n",
      "train mean loss=0.5904525022208691, accuracy=0.8468166666666667\n",
      "test  mean loss=0.5705134539306164, accuracy=0.855\n",
      "epoch 9\n",
      "train mean loss=0.49431484679381055, accuracy=0.86375\n",
      "test  mean loss=0.4764134127646685, accuracy=0.8742\n",
      "epoch 10\n",
      "train mean loss=0.43487690011660257, accuracy=0.8758333333333334\n",
      "test  mean loss=0.41762602001428606, accuracy=0.8854\n",
      "epoch 11\n",
      "train mean loss=0.3939011045793692, accuracy=0.8864\n",
      "test  mean loss=0.3766491936892271, accuracy=0.8936\n",
      "epoch 12\n",
      "train mean loss=0.36335354487101235, accuracy=0.89485\n",
      "test  mean loss=0.3466691667586565, accuracy=0.9012\n",
      "epoch 13\n",
      "train mean loss=0.3392683631678422, accuracy=0.9012833333333333\n",
      "test  mean loss=0.3224241236224771, accuracy=0.9086\n",
      "epoch 14\n",
      "train mean loss=0.31962380203107993, accuracy=0.9065166666666666\n",
      "test  mean loss=0.30361495062708854, accuracy=0.9143\n",
      "epoch 15\n",
      "train mean loss=0.30209932712217175, accuracy=0.9115833333333333\n",
      "test  mean loss=0.28567113189026716, accuracy=0.9196\n",
      "epoch 16\n",
      "train mean loss=0.28743646445373694, accuracy=0.9158\n",
      "test  mean loss=0.2720460768043995, accuracy=0.9233\n",
      "epoch 17\n",
      "train mean loss=0.2743938194712003, accuracy=0.9191\n",
      "test  mean loss=0.2591277867741883, accuracy=0.9272\n",
      "epoch 18\n",
      "train mean loss=0.26266281445821127, accuracy=0.9233\n",
      "test  mean loss=0.2477669803611934, accuracy=0.9311\n",
      "epoch 19\n",
      "train mean loss=0.2512600380430619, accuracy=0.9269166666666667\n",
      "test  mean loss=0.23741716910153626, accuracy=0.9338\n",
      "epoch 20\n",
      "train mean loss=0.24141443323343992, accuracy=0.9296\n",
      "test  mean loss=0.22718115985393525, accuracy=0.9362\n",
      "epoch 21\n",
      "train mean loss=0.2326684372499585, accuracy=0.9323666666666667\n",
      "test  mean loss=0.2185846779681742, accuracy=0.9391\n",
      "epoch 22\n",
      "train mean loss=0.22495164047926663, accuracy=0.9347333333333333\n",
      "test  mean loss=0.21086794381961227, accuracy=0.9418\n",
      "epoch 23\n",
      "train mean loss=0.21632309858997664, accuracy=0.9377833333333333\n",
      "test  mean loss=0.2025779026094824, accuracy=0.9441\n",
      "epoch 24\n",
      "train mean loss=0.20977516214052835, accuracy=0.9394333333333333\n",
      "test  mean loss=0.19670472822152077, accuracy=0.9452\n",
      "epoch 25\n",
      "train mean loss=0.20339250270277262, accuracy=0.9412666666666667\n",
      "test  mean loss=0.19074565844610333, accuracy=0.9468\n",
      "epoch 26\n",
      "train mean loss=0.19601621814693013, accuracy=0.9435333333333333\n",
      "test  mean loss=0.18355124417692423, accuracy=0.9492\n",
      "epoch 27\n",
      "train mean loss=0.190265738243858, accuracy=0.9459833333333333\n",
      "test  mean loss=0.17826744156889618, accuracy=0.9511\n",
      "epoch 28\n",
      "train mean loss=0.18450574899092317, accuracy=0.9472333333333334\n",
      "test  mean loss=0.17232642601244152, accuracy=0.9525\n",
      "epoch 29\n",
      "train mean loss=0.17963365136956175, accuracy=0.9485\n",
      "test  mean loss=0.16762407870031892, accuracy=0.9544\n",
      "epoch 30\n",
      "train mean loss=0.17489689730728666, accuracy=0.9494\n",
      "test  mean loss=0.16273394388146697, accuracy=0.9549\n",
      "epoch 31\n",
      "train mean loss=0.17041757309188446, accuracy=0.9510166666666666\n",
      "test  mean loss=0.15855776734650134, accuracy=0.9573\n",
      "epoch 32\n",
      "train mean loss=0.1661035040517648, accuracy=0.9521833333333334\n",
      "test  mean loss=0.15476704249158502, accuracy=0.9577\n",
      "epoch 33\n",
      "train mean loss=0.16246064273640515, accuracy=0.9533\n",
      "test  mean loss=0.1502455009985715, accuracy=0.9596\n",
      "epoch 34\n",
      "train mean loss=0.15838081860293945, accuracy=0.95515\n",
      "test  mean loss=0.14770618431270122, accuracy=0.9594\n",
      "epoch 35\n",
      "train mean loss=0.15450580097114047, accuracy=0.9559333333333333\n",
      "test  mean loss=0.1437309992313385, accuracy=0.9609\n",
      "epoch 36\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt    #グラフ出力用module\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "WEIGHT_DECAY = 0.005\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCH = 100\n",
    "PATH = \"Datasetのディレクトリpath\"\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root = PATH, train = True, download = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE,\n",
    "                        shuffle = True, num_workers = 2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root = PATH, train = False, download = True, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = BATCH_SIZE,\n",
    "                        shuffle = False, num_workers = 2)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,16,3)\n",
    "        self.conv2 = nn.Conv2d(16,32,3)\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda:0\")\n",
    "net = Net()\n",
    "# net = net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "train_loss_value=[]      #trainingのlossを保持するlist\n",
    "train_acc_value=[]       #trainingのaccuracyを保持するlist\n",
    "test_loss_value=[]       #testのlossを保持するlist\n",
    "test_acc_value=[]        #testのaccuracyを保持するlist \n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    print('epoch', epoch+1)    #epoch数の出力\n",
    "    for (inputs, labels) in trainloader:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    sum_loss = 0.0          #lossの合計\n",
    "    sum_correct = 0         #正解率の合計\n",
    "    sum_total = 0           #dataの数の合計\n",
    "\n",
    "    #train dataを使ってテストをする(パラメータ更新がないようになっている)\n",
    "    for (inputs, labels) in trainloader:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        sum_loss += loss.item()                            #lossを足していく\n",
    "        _, predicted = outputs.max(1)                      #出力の最大値の添字(予想位置)を取得\n",
    "        sum_total += labels.size(0)                        #labelの数を足していくことでデータの総和を取る\n",
    "        sum_correct += (predicted == labels).sum().item()  #予想位置と実際の正解を比べ,正解している数だけ足す\n",
    "    print(\"train mean loss={}, accuracy={}\"\n",
    "            .format(sum_loss*BATCH_SIZE/len(trainloader.dataset), float(sum_correct/sum_total)))  #lossとaccuracy出力\n",
    "    train_loss_value.append(sum_loss*BATCH_SIZE/len(trainloader.dataset))  #traindataのlossをグラフ描画のためにlistに保持\n",
    "    train_acc_value.append(float(sum_correct/sum_total))   #traindataのaccuracyをグラフ描画のためにlistに保持\n",
    "\n",
    "    sum_loss = 0.0\n",
    "    sum_correct = 0\n",
    "    sum_total = 0\n",
    "\n",
    "    #test dataを使ってテストをする\n",
    "    for (inputs, labels) in testloader:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        sum_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        sum_total += labels.size(0)\n",
    "        sum_correct += (predicted == labels).sum().item()\n",
    "    print(\"test  mean loss={}, accuracy={}\"\n",
    "            .format(sum_loss*BATCH_SIZE/len(testloader.dataset), float(sum_correct/sum_total)))\n",
    "    test_loss_value.append(sum_loss*BATCH_SIZE/len(testloader.dataset))\n",
    "    test_acc_value.append(float(sum_correct/sum_total))\n",
    "\n",
    "plt.figure(figsize=(6,6))      #グラフ描画用\n",
    "\n",
    "#以下グラフ描画\n",
    "plt.plot(range(EPOCH), train_loss_value)\n",
    "plt.plot(range(EPOCH), test_loss_value, c='#00ff00')\n",
    "plt.xlim(0, EPOCH)\n",
    "plt.ylim(0, 2.5)\n",
    "plt.xlabel('EPOCH')\n",
    "plt.ylabel('LOSS')\n",
    "plt.legend(['train loss', 'test loss'])\n",
    "plt.title('loss')\n",
    "plt.savefig(\"loss_image.png\")\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(range(EPOCH), train_acc_value)\n",
    "plt.plot(range(EPOCH), test_acc_value, c='#00ff00')\n",
    "plt.xlim(0, EPOCH)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('EPOCH')\n",
    "plt.ylabel('ACCURACY')\n",
    "plt.legend(['train acc', 'test acc'])\n",
    "plt.title('accuracy')\n",
    "plt.savefig(\"accuracy_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
