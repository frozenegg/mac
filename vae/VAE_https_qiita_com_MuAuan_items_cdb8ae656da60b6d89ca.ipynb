{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_https://qiita.com/MuAuan/items/cdb8ae656da60b6d89ca.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzLZuwVVNBOW",
        "outputId": "85e90eb2-9b97-424d-eb74-2a0cceabd879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.layers import Lambda, Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Activation, Flatten\n",
        "from keras.layers import Reshape, Embedding,InputLayer\n",
        "\n",
        "# reparameterization trick\n",
        "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
        "# z = z_mean + sqrt(var)*eps\n",
        "def sampling(args):\n",
        "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
        "    # Arguments\n",
        "        args (tensor): mean and log of variance of Q(z|X)\n",
        "    # Returns\n",
        "        z (tensor): sampled latent vector\n",
        "    \"\"\"\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    # by default, random_normal has mean=0 and std=1.0\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "def plot_results(models,\n",
        "                 data,\n",
        "                 batch_size=128,\n",
        "                 model_name=\"vae_mnist\"):\n",
        "    \"\"\"Plots labels and MNIST digits as function of 2-dim latent vector\n",
        "    # Arguments\n",
        "        models (tuple): encoder and decoder models\n",
        "        data (tuple): test data and label\n",
        "        batch_size (int): prediction batch size\n",
        "        model_name (string): which model is using this function\n",
        "    \"\"\"\n",
        "    encoder, decoder = models\n",
        "    x_test, y_test = data\n",
        "    os.makedirs(model_name, exist_ok=True)\n",
        "\n",
        "    filename1 = \"./mnist1000/vae_mean_all.png\"\n",
        "    # display a 2D plot of the digit classes in the latent space\n",
        "    z_mean, _, _ = encoder.predict(x_test, batch_size=batch_size)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.savefig(filename1)\n",
        "    plt.show()\n",
        "\n",
        "    filename2 = \"./mnist1000/digits_over_latent_all.png\"\n",
        "    # display a 30x30 2D manifold of digits\n",
        "    n = 30\n",
        "    digit_size = 28\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "    # linearly spaced coordinates corresponding to the 2D plot\n",
        "    # of digit classes in the latent space\n",
        "    grid_x = np.linspace(-4, 4, n)\n",
        "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "            x_decoded = decoder.predict(z_sample)\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "            figure[i * digit_size: (i + 1) * digit_size,\n",
        "                   j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range + 1\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure, cmap='Greys_r')\n",
        "    plt.savefig(filename2)\n",
        "    plt.show()\n",
        "\n",
        "def plot_results2(models,\n",
        "                 data,\n",
        "                 batch_size=128,\n",
        "                 model_name=\"vae_mnist\"):\n",
        "    z0=[-0.7,-3]\n",
        "    z7=[-0.7,2]\n",
        "    for t in range(50):\n",
        "        s=t/50\n",
        "        z_sample=np.array([[s*(-0.7)+(1-s)*(-0.7),s*(-3)+(1-s)*2]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        plt.imshow(x_decoded.reshape(28, 28))\n",
        "        plt.title(\"z_sample=\"+str(z_sample))\n",
        "        plt.savefig('./mnist1000/z_sample_t{}'.format(t))\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "# MNIST dataset\n",
        "#(x_train, _), (x_test, _) = mnist.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "image_size = x_train.shape[1]\n",
        "original_dim = image_size * image_size\n",
        "x_train = x_train[:60000].astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train[:60000], (len(x_train[:60000]), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1)) \n",
        "y_train=y_train[:60000]\n",
        "\n",
        "\n",
        "# network parameters\n",
        "#input_shape = (original_dim, )\n",
        "input_shape = (image_size, image_size, 1)\n",
        "intermediate_dim = 512\n",
        "batch_size = 128\n",
        "latent_dim = 2\n",
        "epochs = 100\n",
        "\n",
        "# VAE model = encoder + decoder\n",
        "# build encoder model\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same',name='encoded')(x)\n",
        "shape = K.int_shape(x)\n",
        "print(\"shape[1], shape[2], shape[3]\",shape[1], shape[2], shape[3])\n",
        "x = Flatten()(x)\n",
        "\n",
        "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "# use reparameterization trick to push the sampling out as input\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "# instantiate encoder model\n",
        "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "encoder.summary()\n",
        "\n",
        "# build decoder model\n",
        "# decoder\n",
        "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
        "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "outputs = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# instantiate decoder model\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()\n",
        "\n",
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = Model(inputs, outputs, name='vae_mlp')\n",
        "\n",
        "\n",
        "# loss関数\n",
        "# Compute VAE loss\n",
        "reconstruction_loss = binary_crossentropy(K.flatten(inputs),\n",
        "                                          K.flatten(outputs))\n",
        "reconstruction_loss *= image_size * image_size\n",
        "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')\n",
        "\n",
        "# 学習に使うデータを限定する\n",
        "x_train1 = x_train  #[y_train==7]\n",
        "x_test1 = x_test  #[y_test==7]\n",
        "#vae.load_weights('vae_mnist_weights_100.h5')\n",
        "# encoder.load_weights('encoder_mnist_weights_100.h5')\n",
        "# decoder.load_weights('decoder_mnist_weights_100.h5')\n",
        "\n",
        "# autoencoderの実行\n",
        "vae.fit(x_train1,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                validation_data=(x_test1, None))\n",
        "\n",
        "models = (encoder, decoder)\n",
        "data = (x_test, y_test)\n",
        "\n",
        "plot_results(models,\n",
        "             data,\n",
        "             batch_size=batch_size,\n",
        "             model_name=\"vae_mlp\")\n",
        "\n",
        "plot_results2(models,\n",
        "             data,\n",
        "             batch_size=batch_size,\n",
        "             model_name=\"vae_mlp\")\n",
        "vae.save_weights('vae_mnist_weights_100.h5')\n",
        "encoder.save_weights('encoder_mnist_weights_100.h5')\n",
        "decoder.save_weights('decoder_mnist_weights_100.h5')\n",
        "\n",
        "# 実行結果の表示\n",
        "n = 10\n",
        "decoded_imgs = vae.predict(x_test[:n])\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(n):\n",
        "    # original_image\n",
        "    orig_img = x_test[i].reshape(image_size, image_size)\n",
        "\n",
        "    # reconstructed_image\n",
        "    reconst_img = decoded_imgs[i].reshape(image_size, image_size)\n",
        "\n",
        "    # diff image\n",
        "    diff_img = ((orig_img - reconst_img)+2)/4\n",
        "    diff_img = (diff_img*255).astype(np.uint8)\n",
        "    orig_img = (orig_img*255).astype(np.uint8)\n",
        "    reconst_img = (reconst_img*255).astype(np.uint8)\n",
        "    diff_img_color = cv2.applyColorMap(diff_img, cv2.COLORMAP_JET)\n",
        "\n",
        "    # display original\n",
        "    ax = plt.subplot(3, n,  i + 1)\n",
        "    plt.imshow(orig_img, cmap=plt.cm.gray)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(3, n, i + n + 1)\n",
        "    plt.imshow(reconst_img, cmap=plt.cm.gray)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display diff\n",
        "    ax = plt.subplot(3, n, i + n*2 + 1)\n",
        "    plt.imshow(diff_img, cmap=plt.cm.jet)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.savefig(\"autodetect_all.jpg\")\n",
        "plt.pause(1)\n",
        "plt.close()\n",
        "\n",
        "# 学習結果の保存\n",
        "# vae.save('./ae_mnist.h5')\n",
        "\n",
        "# # json and weights\n",
        "# model_json = vae.to_json()\n",
        "# with open('ae_mnist.json', 'w') as json_file:\n",
        "#     json_file.write(model_json)\n",
        "# vae.save_weights('ae_mnist_weights.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape[1], shape[2], shape[3] 4 4 8\n",
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 16)   160         encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 16)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 14, 14, 8)    1160        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 8)      0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 7, 7, 8)      584         max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "encoded (MaxPooling2D)          (None, 4, 4, 8)      0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 128)          0           encoded[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 2)            258         flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 2)            258         flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,420\n",
            "Trainable params: 2,420\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               384       \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 4, 4, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 14, 14, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 28, 28, 1)         145       \n",
            "=================================================================\n",
            "Total params: 2,865\n",
            "Trainable params: 2,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "469/469 [==============================] - 102s 217ms/step - loss: 225.3470 - val_loss: 182.3914\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 176.1287 - val_loss: 171.7915\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 169.6571 - val_loss: 168.4966\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 166.9867 - val_loss: 166.3213\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 102s 217ms/step - loss: 165.5008 - val_loss: 164.6082\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 102s 217ms/step - loss: 164.2403 - val_loss: 163.4092\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 163.2872 - val_loss: 162.7617\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 162.4767 - val_loss: 162.0399\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 161.8399 - val_loss: 161.4815\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 161.2893 - val_loss: 161.0456\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 160.8831 - val_loss: 160.5244\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 160.4252 - val_loss: 160.0664\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 160.0600 - val_loss: 159.6458\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 159.7151 - val_loss: 159.2504\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 159.4007 - val_loss: 158.9129\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 102s 217ms/step - loss: 159.1373 - val_loss: 159.3931\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 102s 217ms/step - loss: 158.9034 - val_loss: 158.9188\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 102s 217ms/step - loss: 158.6521 - val_loss: 158.4695\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 103s 219ms/step - loss: 158.4104 - val_loss: 157.7015\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 158.2806 - val_loss: 157.9961\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 158.0587 - val_loss: 158.3168\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 157.8863 - val_loss: 157.6680\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 102s 217ms/step - loss: 157.8033 - val_loss: 157.5939\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 157.5330 - val_loss: 157.5950\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 103s 219ms/step - loss: 157.4874 - val_loss: 157.1316\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 157.3260 - val_loss: 157.4048\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 102s 217ms/step - loss: 157.1781 - val_loss: 156.9682\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 157.0867 - val_loss: 156.8366\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 157.0212 - val_loss: 156.5514\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 102s 219ms/step - loss: 156.8556 - val_loss: 157.0173\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 103s 219ms/step - loss: 156.7843 - val_loss: 156.4623\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 103s 219ms/step - loss: 156.5705 - val_loss: 156.1443\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 156.5833 - val_loss: 156.3784\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 103s 219ms/step - loss: 156.4696 - val_loss: 157.2659\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 156.4634 - val_loss: 156.1171\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 102s 218ms/step - loss: 156.4232 - val_loss: 155.9398\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 103s 219ms/step - loss: 156.2433 - val_loss: 155.8567\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 103s 219ms/step - loss: 156.2229 - val_loss: 156.3196\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 156.1179 - val_loss: 155.7354\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 104s 222ms/step - loss: 156.0500 - val_loss: 155.4723\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 156.0330 - val_loss: 156.2664\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.9720 - val_loss: 155.8240\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.8403 - val_loss: 155.8610\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 103s 221ms/step - loss: 155.8050 - val_loss: 156.5381\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 104s 222ms/step - loss: 155.8653 - val_loss: 156.4350\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.7553 - val_loss: 155.6653\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.7675 - val_loss: 155.0674\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 104s 222ms/step - loss: 155.6156 - val_loss: 155.4320\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 104s 222ms/step - loss: 155.5750 - val_loss: 155.5489\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.5397 - val_loss: 155.3384\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.4373 - val_loss: 155.4431\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.4296 - val_loss: 156.7998\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.4682 - val_loss: 155.1938\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.4182 - val_loss: 155.2813\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.4017 - val_loss: 155.5883\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.2877 - val_loss: 154.9381\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.2439 - val_loss: 155.2213\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.2803 - val_loss: 154.7458\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 104s 221ms/step - loss: 155.2056 - val_loss: 155.3519\n",
            "Epoch 60/100\n",
            "158/469 [=========>....................] - ETA: 1:05 - loss: 154.8765"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iyh-EW3rNEhD"
      },
      "source": [
        "# 学習に使うデータを限定する\n",
        "x_train1 = x_train[y_train==7]\n",
        "x_test1 = x_test[y_test==7]\n",
        "\n",
        "vae.fit(x_train1,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                validation_data=(x_test1, None))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}